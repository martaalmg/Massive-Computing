{"cells":[{"cell_type":"markdown","source":["# FINAL PRACTICAL WORK 2022/23\n## IMPLEMENT BRIN AND PAGE’S PAGERANK ALGORITHM \n\n### Gracia Estrán Buyo \n#### 100452014\n\n### Marta Almagro Fuello \n#### 100451979"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9b71e48f-d338-43c8-baee-750a100f0eaa","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##### First, we import all the libraries that are going to be usefull during this assigment:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b429d52e-a2c6-427b-aa94-bde7eb5325e8","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport re"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"000ae955-cd3b-4a52-9e0c-978241c38d5c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"10865609-2787-4474-900b-54e4dd830765","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7ae6143a-d173-4019-861b-e9955817c173","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Create a Spark DataFrame from those parquet files with the command:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"14d5a5cb-37b4-41f8-a28f-99343aee92c0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#%fs ls dbfs:/databricks-datasets/wikipedia-datasets/data-001/en_wikipedia\n#%fs ls dbfs:/databricks-datasets/wikipedia-datasets/data-001/en_wikipedia/articles-only-parquet\n\nwikipediaDF = spark.read.parquet(\"dbfs:/databricks-datasets/wikipedia-datasets/data-001/en_wikipedia/articles-only-parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c3d78fa8-0b79-4931-b6ad-9a3f9b595d86","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### It is going to be useful for later to know the total of pages we are going to work with"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a8a175ea-2379-43ec-bcf3-b1535fac90be","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["N = wikipediaDF.count() #5823210"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e16e48be-33f7-47c7-8265-a94866829c01","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Instead to use the full database, it is recommended to use a smaller version to analyse the structure, with 0.01% of records (approx. 582 records):"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d514c6bb-9ff1-4de1-8034-3f6d8df5f554","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["PartialWikipediaDF = wikipediaDF.sample(fraction = 0.001, seed = 123).cache()\nM = PartialWikipediaDF.count() #71\n#display(PartialWikipediaDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8f1bd9c8-7f2f-4780-b338-8e55fbd947a1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### The parse_links function was already created and it is to locate the links in the text."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aed5eb62-2d7e-4b11-8f63-b8abe00a2029","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def parse_links(document_body):\n    data = re.findall(r'\\[\\[(.+?)\\]\\]', document_body)\n    if (len(data)>0):\n        links = [s.lower() for s in data]\n    else:\n        links = []\n    return links"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"77276afc-1f7c-4a23-860c-c923682a882e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### As the functions are no callable from the Spark Database we define the User Defined Function, this will be done for every function we create from here."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ab1202ba-f7d7-4e40-ae07-d84a01aea7d4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["parse_links_udf = udf(parse_links, ArrayType(StringType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"91652eea-ca38-4c8d-9291-7ad0f60fd66f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["tolower_udf= udf(lambda x: x.lower()) "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9c9ce40-6272-43bc-b370-eb7f6ee6ecce","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Create the dataset with the important information (“title”, “id” and “text”) which we are going to use to create the forward and reverse matrix:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5536767c-7153-4337-afe1-5c794540c4f2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data = PartialWikipediaDF.select(tolower_udf(PartialWikipediaDF[\"title\"]).alias(\"title\"),\n                                 PartialWikipediaDF[\"id\"],\n                                 parse_links_udf(PartialWikipediaDF[\"text\"]).alias(\"links\")).cache()\n#display(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"42ae3725-3c11-4190-b0e0-e220827c6361","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### This variable is created to help us get the forward matrix and in the final table to provide the title next to the id with its pagerank:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e6cfd450-2de2-462c-b565-e56e2714020c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["title_idDF = wikipediaDF.select(tolower_udf(wikipediaDF[\"title\"]).alias(\"title\"), wikipediaDF[\"id\"])\ntitle_idPDF = title_idDF.toPandas()\n#display(title_idDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dbf50ad5-618a-4976-8aca-9bc7a8ac6fb2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Also there are going to be many variables that are made broadcast so we dont have to give them as an argument and we can access to them whenever we need it."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"65870fb8-fa93-48e8-a2b2-40be02b47d26","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["broadcast_title_idPDF = sc.broadcast(title_idPDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e6e0245b-2b87-4fba-9094-3e37f5591374","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def titles2id(links):\n  data_titles = broadcast_title_idPDF.value\n  if (len(links)>0):\n    ids = data_titles[data_titles.title.isin(links)].id.to_list()\n  else:\n    ids = []\n  return list(set(ids))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1820edc1-5679-4e6d-8554-1cbc58633045","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["titles2id_UDF = udf(titles2id, ArrayType(LongType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f27980ff-73a9-4c3c-bcbf-711577e64926","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### A table with the id of each web and all the ids of the links that go out of it (ForwardDF):"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d955b6ce-ce0d-4f68-adc3-d91504e8fea7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["ForwardDF = data.select(data[\"id\"], titles2id_UDF(data[\"links\"]).alias(\"links\")).cache()\n#display(ForwardDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"138cb3fc-65c0-45df-84b6-ddcc69099d1c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### We also are going to get the number of links that go out of each document, will be stored in the OutgoingsLinksCounter matrix:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8f9c0997-5603-4aa4-a53f-361a04276882","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def count_links(links):\n  return len(links)\n\ncount_links_udf = udf(count_links, LongType())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"540a8733-7e38-4e0c-b22d-fc8e24c5bd73","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["OutgoingsLinksCountersDF = ForwardDF.select(ForwardDF[\"id\"], count_links_udf(ForwardDF[\"links\"]).alias(\"count\"))\nOutgoingsLinksCountersPDF = OutgoingsLinksCountersDF.toPandas()\n#display(OutgoingsLinksCountersDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d8a99d64-8832-4446-99be-fa06be9ec74b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### We will make it broadcast again as before:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"de391dbb-e00b-402d-87fa-d23dfb3ad355","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["OutgoingsLinksCounters_BV = sc.broadcast(OutgoingsLinksCountersPDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"28b9ca2a-1d31-49d3-8593-f5934bb46921","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### In order to get the ReverseDF first for each id we return a new row for each element in the given array of links (TemporalReverseLink):"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a18b1740-9fa6-4f0f-9813-255da7e079fd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["TemporalReverseLinks = ForwardDF.select(\"id\", explode(\"links\").alias(\"links\"))\nReverseDF = TemporalReverseLinks.groupBy(\"id\").agg(collect_list (\"id\").alias(\"links\")).cache()\n#display(ReverseDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1bcf8dbb-c979-4345-af8f-4d43da5b94b8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### The PageRank algorithm says that anyone who is on the Internet and is clicking random pages, will stop clicking because a page will not direct to any other. The probability for this person to continue clicking is the damping factor which is usually set at 0.85.\n\n##### To do our current page rank data frame, we can first of all select the first column of ReverseDF, that has the links that we will use. Then we create N, that is the number of links that we have. And by doing so, we can add our other column, the page rank, which is the dumping factor divided by N. It will obviously be the same for each link. \n##### Finally, we create a broadcast variable with N that will be used in the future."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b6c19d4f-7ea5-43d5-a18c-d670ddc31613","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["pageRankDF = ReverseDF.select(ReverseDF[\"id\"])\npageRankPDF = pageRankDF.toPandas()\nN = pageRankDF.count()\n\ntotal_N = N*np.ones(N)\n\npageRankPDF[\"PR\"] = pd.Series(0.85/total_N)\n\nN = sc.broadcast(N)\ndisplay(pageRankPDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11a558dc-b43f-4998-a92b-1eb9921c5482","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Now that we have the current page rank of each id, which is the same because we have not execute the function yet, we can start coding the page rank function. It will compute it by calculating how many pages can take a link. To accomplishh that we created a loop that goes through each link in links and calculates how many pages can take that link.\n\n##### We check if each link from the list od ids appears on the current page rank.  We check if there exist those ids in our current_page_rank and if we have more than one or one page linked to that id we set it as the pagerank of the current page and if it does not have any link with that id we set it to 0. We do the same with the counter.\n\n##### Where \"current_pr\" is used to find the value of our page rank and \"counter\" to count, so we can express \"new_pr\" as the pagerank from before plus the current_pr/counter. After adding all the values of each links to new_pr, we apply the formula with the damping factor 0.85 and N values.\n\n##### It will also return the difference between the rank of the current_id and the new_pr that we have calculated in order to check if the substraction is more or less than the tolerance number chosen.\n\n##### Now we can perform the operation that defines the page rank algorithm."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7a864f52-aa5c-4c4a-a246-724249f7a74e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def new_pagerank(list_of_ids, current_id, current_page_rank):   \n  new_pr = 0                                            \n  counts = OutgoingsLinksCounters_BV.value   \n  \n  # Go through every id in the list\n  for i in list_of_ids: \n    \n    # Get current_pr:\n    current_pr = current_page_rank[current_page_rank[\"id\"] == i]     \n    \n    if len(current_pr)>0:                                            \n      current_pr = current_pr.iloc[0][1]                                     \n    else:                                                     \n      current_pr = 0      \n      \n    # Get counter:\n    counter = counts[counts[\"id\"] == i]     \n    \n    if len(counter)>0:                                           \n      counter = counter.iloc[0][1] \n      \n      # Get the pagerank:\n      new_pr += current_pr/counter   \n  \n  # Get value of the pagerank:\n  new_pr = (1-0.85)/N.value + 0.85 * new_pr \n  \n  # Get the difference:\n  difference = abs(new_pr - current_page_rank[current_page_rank[\"id\"] == current_id].iloc[0][\"PR\"])   \n  \n  return [float(new_pr), float(difference)]    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"95d85383-fd55-400d-86c1-02e04a0258c9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### The next step is a while loop to iterate and find the page rank of each link, which will stop if the absolute value of the difference (which is the substraction of the old pagerank minus the new) is more than the tolerance that we chose (0.000001) or if it reaches a maximum of iterations, 20.\n\n##### To do so, we have to change the function into a UDF, create the demanded final dataframe with the id and the page rank value, and then transform it to a pandas data frame.\n\n##### Finally we update the number of iterations that have been done, and the new pagerank is now the current."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6714047c-e0b1-48fe-b6d4-c66f6b009672","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["max_it = 20             \ntolerance = 0.0000001  \ncount = 0\nstop = True\n\nwhile count < max_it and stop == True:                                                               \n  stop = False \n  \n  # Create the user define function for new page rank:\n  new_pagerank_udf = udf(lambda l, i: new_pagerank(l, i, PageRankPDF), ArrayType(FloatType()))   \n  \n  # We store the difference and pagerank columns in the variable solutions:\n  Solutions = ReverseDF.select(ReverseDF[\"id\"], new_pagerank_udf(ReverseDF[\"links\"], ReverseDF[\"id\"]).alias(\"PR\"))  \n  \n  # Create the new page rank dataframe with the id, pagerank and difference:\n  NewPageRankDF = Solutions.select(\"id\", Solutions.PR[0].alias(\"PR\"), Solutions.PR[1].alias(\"difference\"))\n  display(NewPageRankDF)\n  # Transform to pandas:\n  PageRankPDF = NewPageRankDF.toPandas()                                                       \n  \n  # Chech tolerance:\n  for i in PageRankPDF[\"difference\"]:       \n    if i >= tolerance:                \n      stop = True    \n      \n  # Update:    \n  count += 1\n  print(\"Step:\", count)                "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"92a8e082-6ee6-4721-ba11-5f1afedfebe2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Since we also want the titles of each link, we perform a final piece of code to do so. With that, we have our final data frame that only has to be converted to Pandas."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ae73936d-664c-4211-b0d7-b5d114d05595","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["FinalPageRankPDF = PageRankPDF.filter([\"id\", \"PR\"]).copy()\nids_1 = FinalPageRankPDF.id.to_list()\ntitles = []\n\nfor j in ids_1:\n    bool1 = list(j==FinalPageRankPDF['id'])\n    l = 0\n    n = 0\n    for i in bool1:\n        if i == True:\n            l = n\n            h = title_idPDF.iloc[l]['title']\n            titles.append(h)\n        n+=1\n\nFinalPageRankPDF['title'] = pd.Series(titles)\ndisplay(FinalPageRankPDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c56e3a52-c8f4-4c67-ada7-47a2ba6d0190","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Conclusion\n\n\n##### We could observe that with a larger tolerance and more iterations this project would take much more time that what is already taking, so we started doing it with less iterations where every execution were faster but not as effective than with 20 iterations.\n\n##### This has been a challenging project but after many hours and the explanations given in class we have been able to modify the code given, so we worked more confortable with our own functions. We investigated more about the PageRank Algorithm and we actually were able to understand how other websites use this algorithm.\n\n##### Also at the beginning we werent sure about the User Defined Functions and why the python functions worked like that but after this project we got it pretty good and gained confident for the next time we have to use Spark, which in my case I believe is going to be soon as I am going to start an internship where the knowledge of Apache Spark was valuable."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"94b9d343-86f1-49b3-b2e0-d9d89849dc56","inputWidgets":{},"title":""}}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.11","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"FinalWork","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2666298675146252,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":2666298675146243}},"nbformat":4,"nbformat_minor":0}
