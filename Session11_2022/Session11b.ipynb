{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Participants:\n",
        "Marta Almagro Fuello: 100451979\n",
        "\n",
        "Gracia Estrán Buyo: 100452014"
      ],
      "metadata": {
        "id": "UPdJS-NLFCOQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP7FuserO7nO"
      },
      "source": [
        "# Comparision between classical Matrix Multiplication Algorithm and Tiled Matrix Multiplication\n",
        "\n",
        "In this practical work we will compare these two algorithms, and check how the memory access impacts in the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmBjfAoBVsKr"
      },
      "source": [
        "These 2 cells will help us to know which hardware have assigned, to decide the block size in iur parallel algorithm.\n",
        "\n",
        "Sometimes the 256 threads per block (16x16 threads) are the bes compromise solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "neJamrihGmPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad287e35-0643-4c0b-d883-77e8069dabbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 7.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.12.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (4.13.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda) (3.9.0)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.1-cp37-cp37m-linux_x86_64.whl size=629701 sha256=75df20950bc2f24dd8a216b3d9970e833eb86c34bfa8b9e98e64aac01285f65e\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/53/c9/caa05618e686df51f017d8a9923f38d915ce31df67ab6628e6\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.12-py2.py3-none-any.whl size=65034 sha256=875c238407558d7533f040651be7dece6b512d2374a88d86bf3d697377943f2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/5e/9e/76d7430e116b7cab0016fbabb26b896daae1946a3f7dea9915\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: platformdirs, pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.3 platformdirs-2.5.2 pycuda-2022.1 pytools-2022.1.12\n"
          ]
        }
      ],
      "source": [
        "#Uncomment the follow line if you are running in Google Colaboratory\n",
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85bb78nqYanS"
      },
      "source": [
        "Import the necessary modules, as pycuda, numpy and time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aH8z7V4sGzJx"
      },
      "outputs": [],
      "source": [
        "import  numpy  as  np\n",
        "import  pycuda.autoinit\n",
        "from    pycuda.compiler import SourceModule\n",
        "import  pycuda.driver as  drv\n",
        "import  pycuda.gpuarray as  gpuarray\n",
        "import  pycuda.tools as gtools\n",
        "from numpy import linalg as la\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mDwt5WwYniI"
      },
      "source": [
        "# FIRST KERNEL: simple matrices multiplication\n",
        "This kernel will recive 3 matrices: a and b are the source matrices, and c is where we will store the result.\n",
        "\n",
        "The size of the matrix a is $m *n$.\n",
        "\n",
        "The size of the matrix b is $n * o$.\n",
        "\n",
        "The size of the matrix c is $m * o$.\n",
        "\n",
        "All three matrices are stored in a row-wise vector. \n",
        "\n",
        "Each thread will have assigned one cell position in the matrix c. The formulae for both coordinates are:\n",
        "\n",
        "\n",
        "$idxY = blockIdx.y*blockDim.y+threadIdx.y$\n",
        "\n",
        "$idxX = blockIdx.x*blockDim.x+threadIdx.x$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rAyzw3qiG3sb"
      },
      "outputs": [],
      "source": [
        "kernel  =  SourceModule (\"\"\"\n",
        "__global__ void matrix_mult(float* a, \n",
        "                            float* b, \n",
        "                            float* c, \n",
        "                            int m, \n",
        "                            int n, \n",
        "                            int o) \n",
        "{ \n",
        "  // a is the vector which represents the matrix_a\n",
        "  // b is the vector which represents the matrix_b\n",
        "  // c is the vector where we will store the resulting matrix\n",
        "  // m is number of rows of matrix a\n",
        "  // n is the number of columns of matrix a, and number of rows of matrix b\n",
        "  // o is the number of columns of matrix b\n",
        "  // First task: Using threadIdx.x, threadIdx.y, blockDim.x, blockDim.y, \n",
        "  // blockIdx.x, blockDim.y identify the coordinates x and y in the result matrix\n",
        "  // implements the matrix multiplication, cell by cell using the conventional code and analyze\n",
        "\n",
        "  int idxX;\n",
        "  int idxY;\n",
        "  int idxZ;\n",
        "  int offA;\n",
        "\n",
        "  float s;\n",
        "\n",
        "  idxY = blockIdx.y*blockDim.y+threadIdx.y; //With this we calculate the row address in target matrix\n",
        "  idxX = blockIdx.x*blockDim.x+threadIdx.x; //Here we calculate the column address in target matrix\n",
        "\n",
        "\n",
        "  if ( idxX < o && idxY < m ){    //Here we verify the row address and column address are valid\n",
        "    idxZ = idxY*o + idxX;         //Here we calculate the target vector address, \n",
        "                                  //asuming it is a row wise matrix representation\n",
        "    s = 0;                        //Initialize the s acumulator\n",
        "\n",
        "    offA = idxY*n;                //We calculate the offset of row in matrix a row wise representation\n",
        "                                  //This is to reduce the number of calculae in the next for\n",
        "\n",
        "    for ( int i =0; i<n; i++)     //Here we run through the a columns, b rows\n",
        "      s += a[offA+i]*b[(i*o)+idxX];\n",
        "    \n",
        "    c[idxZ]=s;\n",
        "  }\n",
        "  \n",
        "}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9N8dWR7Zr86"
      },
      "source": [
        "We fetch the cuda function matrix_mult and assign a python reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9pycG9EPHGzY"
      },
      "outputs": [],
      "source": [
        "matrix_mult= kernel.get_function(\"matrix_mult\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7njm6KUZ9o3"
      },
      "source": [
        "For the first case, we creates 3 matrices of size 1024 * 1024 (this is for a fair play comparation with the tiled matrix multiplication)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V24n9UCsa2H6"
      },
      "outputs": [],
      "source": [
        "numRowsA=1024\n",
        "numColsA=1024\n",
        "numRowsB=1024\n",
        "numColsB=1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1FnI8U9WHMMQ"
      },
      "outputs": [],
      "source": [
        "matrix_a=np.random.randn(numRowsA,numColsA).astype(np.float32)\n",
        "matrix_b=np.random.randn(numRowsB,numColsB).astype(np.float32)\n",
        "matrix_c=np.zeros((numRowsA,numColsB),dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8L8R_NhaFzK"
      },
      "source": [
        "Here, we upload the matrices to the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nBQrVcZtHTOk"
      },
      "outputs": [],
      "source": [
        "matrix_a_gpu=gpuarray.to_gpu(matrix_a)\n",
        "matrix_b_gpu=gpuarray.to_gpu(matrix_b)\n",
        "matrix_c_gpu=gpuarray.to_gpu(matrix_c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65alV0m8aKHS"
      },
      "source": [
        "We define a block execution size of 16x16x1 threads. It will allocates 256 threads per block < 1024 which is the most common maximum threads per block.\n",
        "\n",
        "Additionally, Most GPUs have a multiple core number of 256. This allow us to have the maximum number of blox in execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kxm2nOdbHsIE"
      },
      "outputs": [],
      "source": [
        "block_size=(16,16,1) #We take this value to get up to 256 parallel threads per block \n",
        "                     #This will allow us to get up to 9 parallel blocks in execution in a K80\n",
        "                     #10 parallel blocks in execution in a T4\n",
        "                     #14 parallel blocks in execition in a GTX 1080 Ti\n",
        "                     #17 parallel blocks in execition in a RTX 2080 Ti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ud1vc1atsp"
      },
      "source": [
        "We calculate the number of blocks in x axis we will need, as well the number of blocks in y axis.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dddaiUJeHun9"
      },
      "outputs": [],
      "source": [
        "numblocks_x=int(np.ceil(numColsB/16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gmKVRpAFHw7Y"
      },
      "outputs": [],
      "source": [
        "numblocks_y=int(np.ceil(numRowsA/16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd3BmB1Abh0C"
      },
      "source": [
        "Here, we define the grid size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ktsa4_J-Hx4d"
      },
      "outputs": [],
      "source": [
        "grid_size=(numblocks_x,numblocks_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-ygw14vbnrD"
      },
      "source": [
        "And execute our matrices multiplication algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8jgeWyPdH07s"
      },
      "outputs": [],
      "source": [
        "start_t = time.time()\n",
        "matrix_mult(matrix_a_gpu,\n",
        "            matrix_b_gpu,\n",
        "            matrix_c_gpu,\n",
        "            np.int32(numRowsA),\n",
        "            np.int32(numColsA),\n",
        "            np.int32(numColsB),\n",
        "            block=block_size,\n",
        "            grid=(numblocks_x,numblocks_y))\n",
        "end_t = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUkzazBycbzO"
      },
      "source": [
        "Calculates the time it uses "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iHoQIDAkTvA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a074101-106b-4692-ddd1-a1c6337fe053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time processing: 0.0018801689147949219 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"Time processing: {0} seconds\".format(end_t-start_t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrPDz9Aicgyf"
      },
      "source": [
        "And get the C result matrix, to compare with the locally computed result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4d1vBPYYIoHg"
      },
      "outputs": [],
      "source": [
        "matrix_c_final=matrix_c_gpu.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o716_8FeQajS"
      },
      "outputs": [],
      "source": [
        "d = np.matmul(matrix_a,matrix_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xH54kWgeVwIV"
      },
      "outputs": [],
      "source": [
        "MSE = np.sum(np.sum(np.power(matrix_c_final-d,2)))/(d.shape[0]*d.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "w4XcZMDmZD1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4e6bff-5807-4346-d0a2-fa79ba43838e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error: 3.4938357762470673e-10\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean Square Error: {0}\".format(MSE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "46iD5OWP1pIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f395de-8e02-4508-fe6a-ee97f2637f38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019140251"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "la.norm(matrix_c_final-d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GKyOs2VLTkpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6472b8bf-058f-49b7-b2eb-4a7e1a9bee7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.23125267e+01,  3.67383499e+01, -2.99956665e+01,\n",
              "        -3.45916061e+01, -2.92059059e+01, -2.44092426e+01,\n",
              "         3.27181745e+00,  4.72440529e+01,  3.31779327e+01],\n",
              "       [ 7.32669830e+00,  5.68259321e-02, -4.18285275e+00,\n",
              "        -2.37644863e+01, -3.24902611e+01,  3.21666946e+01,\n",
              "        -1.20793664e+00, -9.60221958e+00,  2.28222618e+01],\n",
              "       [-2.84691715e+01, -2.13265114e+01,  1.03802233e+01,\n",
              "        -4.61409903e+00, -2.47352982e+01,  8.26731110e+00,\n",
              "         1.00101366e+01, -7.72007799e+00, -5.75500345e+00],\n",
              "       [ 9.77897358e+00, -3.21664505e+01,  1.43078213e+01,\n",
              "        -3.78362617e+01,  2.56115913e+00, -6.56047440e+01,\n",
              "         5.96568632e+00,  8.74001884e+00,  5.66848259e+01],\n",
              "       [-4.50232201e+01,  1.36028280e+01, -4.12081337e+01,\n",
              "        -3.52544937e+01, -1.31826725e+01, -1.00145073e+01,\n",
              "         1.46483641e+01,  1.49182236e+00,  2.58779602e+01],\n",
              "       [-2.68746681e+01,  2.64852886e+01, -8.86370277e+00,\n",
              "        -2.82666612e+00, -5.61382675e+01,  5.35387535e+01,\n",
              "         1.69391975e+01, -2.58613358e+01,  3.82583046e+01],\n",
              "       [ 9.37365913e+00, -3.38696213e+01, -3.88930917e+00,\n",
              "        -5.00180006e+00, -3.81671381e+00, -4.77321777e+01,\n",
              "         3.35055008e+01,  5.13367424e+01, -3.41010208e+01],\n",
              "       [-1.74809399e+01,  1.62660179e+01,  1.83457642e+01,\n",
              "        -4.65428352e+00, -2.66835365e+01, -3.01124692e+00,\n",
              "        -6.41485834e+00,  2.16552086e+01,  3.62971878e+01],\n",
              "       [-1.66244853e+00,  4.77982559e+01, -4.12872124e+00,\n",
              "        -3.56020546e+01,  3.44015160e+01, -2.37289696e+01,\n",
              "        -4.34368019e+01,  4.38117599e+00,  1.26031265e+01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "matrix_c_final[290:299,90:99]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "f1SsQk1wTrNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ca8318-ada4-486a-bf2e-2e9733170c85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.2312525e+01,  3.6738335e+01, -2.9995686e+01, -3.4591621e+01,\n",
              "        -2.9205902e+01, -2.4409264e+01,  3.2718010e+00,  4.7244072e+01,\n",
              "         3.3177925e+01],\n",
              "       [ 7.3267031e+00,  5.6836128e-02, -4.1828618e+00, -2.3764481e+01,\n",
              "        -3.2490257e+01,  3.2166679e+01, -1.2079239e+00, -9.6022148e+00,\n",
              "         2.2822271e+01],\n",
              "       [-2.8469173e+01, -2.1326492e+01,  1.0380196e+01, -4.6141052e+00,\n",
              "        -2.4735275e+01,  8.2673168e+00,  1.0010129e+01, -7.7200680e+00,\n",
              "        -5.7549934e+00],\n",
              "       [ 9.7789621e+00, -3.2166466e+01,  1.4307817e+01, -3.7836269e+01,\n",
              "         2.5611515e+00, -6.5604736e+01,  5.9657021e+00,  8.7400198e+00,\n",
              "         5.6684837e+01],\n",
              "       [-4.5023228e+01,  1.3602837e+01, -4.1208122e+01, -3.5254501e+01,\n",
              "        -1.3182658e+01, -1.0014510e+01,  1.4648371e+01,  1.4918251e+00,\n",
              "         2.5877937e+01],\n",
              "       [-2.6874668e+01,  2.6485275e+01, -8.8637009e+00, -2.8266144e+00,\n",
              "        -5.6138298e+01,  5.3538719e+01,  1.6939196e+01, -2.5861328e+01,\n",
              "         3.8258308e+01],\n",
              "       [ 9.3736486e+00, -3.3869621e+01, -3.8893089e+00, -5.0017996e+00,\n",
              "        -3.8167088e+00, -4.7732174e+01,  3.3505486e+01,  5.1336746e+01,\n",
              "        -3.4101040e+01],\n",
              "       [-1.7480955e+01,  1.6266020e+01,  1.8345764e+01, -4.6542783e+00,\n",
              "        -2.6683531e+01, -3.0112343e+00, -6.4148731e+00,  2.1655218e+01,\n",
              "         3.6297195e+01],\n",
              "       [-1.6624489e+00,  4.7798218e+01, -4.1287107e+00, -3.5602051e+01,\n",
              "         3.4401520e+01, -2.3728970e+01, -4.3436821e+01,  4.3811698e+00,\n",
              "         1.2603130e+01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "d[290:299,90:99]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46VgrfmqfqRp"
      },
      "source": [
        "# Analysis\n",
        "The Problem with the previous code is the memory access is no coalesced.<br>\n",
        "\n",
        "![image.png](attachment:f31c927a-80fe-4bd4-90ac-074ff2f0f00a.png)\n",
        "\n",
        "\n",
        "So, there is an algorithm which allows an smart memory handling, using the shared memory tiling: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AwE5Pgsdr7pv"
      },
      "outputs": [],
      "source": [
        "kernel_code_template = \"\"\"\n",
        "__global__ void MatrixMulKernel(float *A, float *B, float *C)\n",
        "{\n",
        "\n",
        "  const uint wA = %(MATRIX_A_COLS)s; //This is different because they are not square matrices\n",
        "  const uint wB = %(MATRIX_B_COLS)s;  \n",
        "\n",
        "  // Block index\n",
        "  const uint bx = blockIdx.x;\n",
        "  const uint by = blockIdx.y;\n",
        "\n",
        "  // Thread index\n",
        "  const uint tx = threadIdx.x;\n",
        "  const uint ty = threadIdx.y;\n",
        "\n",
        "  // Index of the first sub-matrix of A processed by the block\n",
        "  const uint aBegin = wA * %(BLOCK_SIZE)s * by;\n",
        "  // Index of the last sub-matrix of A processed by the block\n",
        "  const uint aEnd = aBegin + wA - 1;\n",
        "  // Step size used to iterate through the sub-matrices of A\n",
        "  const uint aStep = %(BLOCK_SIZE)s;\n",
        "\n",
        "  // Index of the first sub-matrix of B processed by the block\n",
        "  const uint bBegin = %(BLOCK_SIZE)s * bx;\n",
        "  // Step size used to iterate through the sub-matrices of B\n",
        "  const uint bStep = %(BLOCK_SIZE)s * wB;\n",
        "\n",
        "  // The element of the block sub-matrix that is computed\n",
        "  // by the thread\n",
        "  float Csub = 0;\n",
        "  // Loop over all the sub-matrices of A and B required to\n",
        "  // compute the block sub-matrix\n",
        "  for (int a = aBegin, b = bBegin;\n",
        "       a <= aEnd;\n",
        "       a += aStep, b += bStep) \n",
        "    {\n",
        "      // Shared memory for the sub-matrix of A\n",
        "      __shared__ float As[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "      // Shared memory for the sub-matrix of B\n",
        "      __shared__ float Bs[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "\n",
        "      // Load the matrices from global memory to shared memory\n",
        "      // each thread loads one element of each matrix\n",
        "      As[ty][tx] = A[a + wA * ty + tx];\n",
        "      Bs[ty][tx] = B[b + wB * ty + tx];\n",
        "      // Synchronize to make sure the matrices are loaded\n",
        "      __syncthreads();\n",
        "\n",
        "      // Multiply the two matrices together;\n",
        "      // each thread computes one element\n",
        "      // of the block sub-matrix\n",
        "      for (int k = 0; k < %(BLOCK_SIZE)s; ++k)\n",
        "        Csub += As[ty][k] * Bs[k][tx];\n",
        "\n",
        "      // Synchronize to make sure that the preceding\n",
        "      // computation is done before loading two new\n",
        "      // sub-matrices of A and B in the next iteration\n",
        "      __syncthreads();\n",
        "    }\n",
        "\n",
        "  // Write the block sub-matrix to global memory;\n",
        "  // each thread writes one element\n",
        "  const uint c = wB * %(BLOCK_SIZE)s * by + %(BLOCK_SIZE)s * bx;\n",
        "  C[c + wB * ty + tx] = Csub;\n",
        "}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgEkH7o3dqag"
      },
      "source": [
        "### Steps\n",
        "Here, we define the number of rows and columns of both matrices. In this case, we have specified the dimension 1024x512 for the matrix A and 512x1024 for the matrix B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "OfbKneZb1qgn"
      },
      "outputs": [],
      "source": [
        "rows_a=1024\n",
        "cols_a=50\n",
        "rows_b=50\n",
        "cols_b=1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk9prSYVpRJn"
      },
      "source": [
        "We create matrix_a and matrix_b with its corresponding dimensions, filled with random numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "BxM8uloE1qgn"
      },
      "outputs": [],
      "source": [
        "matrix_a=np.random.randn(rows_a,cols_a).astype(np.float32)\n",
        "matrix_b=np.random.randn(rows_b,cols_b).astype(np.float32)\n",
        "matrix_c=np.zeros((rows_a,cols_b),dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "2mTJppzox_Ke"
      },
      "outputs": [],
      "source": [
        "# define size of blocks and tiles sub-matrix \n",
        "# (we assume that the block size is same as tile size)\n",
        "TILE_SIZE = 16\n",
        "BLOCK_SIZE = TILE_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEuruFYKeDuB"
      },
      "source": [
        "This is a trick, to replace in our original code the constants MATRIX_A_SIZE, MATRIX_B_SIZE and BLOCK_SIZE, for it values.\n",
        "\n",
        "It allows us change the matriz sizes without change the original code.\n",
        "\n",
        "It is not CUDA trick, its a python trick  using strings and % parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "kDnK1ppeyT_o"
      },
      "outputs": [],
      "source": [
        "# get the kernel code from the template \n",
        "# by specifying the constants MATRIX_A_SIZE, MATRIX_B_SIZE, and BLOCK_SIZE\n",
        "#We call the number of columns of matrices A and B instead of the size of each matrix.\n",
        "kernel_code = kernel_code_template % { \n",
        "    'MATRIX_A_COLS': cols_a,\n",
        "    'MATRIX_B_COLS': cols_b,\n",
        "    'BLOCK_SIZE': BLOCK_SIZE\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8SZ41PPeloP"
      },
      "source": [
        "Here,we compile the kernel code, geting the kernel function reference, in matrixmul."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "RWBmmkcJyW-V"
      },
      "outputs": [],
      "source": [
        "# compile the kernel code\n",
        "mod = SourceModule(kernel_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amybVq7Vd12v"
      },
      "source": [
        "Then we have to crate our matrix_a and matrix_b to be used in this algorithm, and upload to the GPU, for this algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "hNcCouYwyHDL"
      },
      "outputs": [],
      "source": [
        "#We copy our matrices and upload them to de GPU for this algorithm\n",
        "a_cpu = matrix_a\n",
        "b_cpu = matrix_b\n",
        "\n",
        "# compute reference on the CPU to verify GPU computation\n",
        "c_cpu = np.dot(a_cpu, b_cpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNGNpW5V1qgo"
      },
      "source": [
        "Instead to create a host matrix c with zeroes, we can reserve the memory in the GPU, after we can copy the results from the memory to a new local variable.<br/>\n",
        "This will reduce the amount of data to upload (and the time its taken)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "KBeTT-efyKoP"
      },
      "outputs": [],
      "source": [
        "# transfer host (CPU) memory to device (GPU) memory \n",
        "a_gpu = gpuarray.to_gpu(a_cpu) \n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "# create empty gpu array for the result (C = A * B)\n",
        "c_gpu = gpuarray.empty((rows_a, cols_b), np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Uk9O5-5-ybPc"
      },
      "outputs": [],
      "source": [
        "# get the kernel function from the compiled module\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_YwZIad1qgp"
      },
      "source": [
        "Now, we define the blocksize and grid size parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "YQhIZPz61qgp"
      },
      "outputs": [],
      "source": [
        "block_size=(int(TILE_SIZE),int(TILE_SIZE),1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Yg3ccnVg1qgp"
      },
      "outputs": [],
      "source": [
        "gris_size=(int(np.ceil(cols_a/TILE_SIZE)),int(np.ceil(cols_b/TILE_SIZE)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLxecMfke1SQ"
      },
      "source": [
        "Invokes the matrices multiplication kernel, and measure the timming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Su5q48JJydTO"
      },
      "outputs": [],
      "source": [
        "# call the kernel on the card\n",
        "start_t = time.time()\n",
        "matrixmul(\n",
        "    # inputs\n",
        "    a_gpu, b_gpu, \n",
        "    # output\n",
        "    c_gpu, \n",
        "    # grid of multiple blocks\n",
        "    grid = grid_size,\n",
        "    # block of multiple threads\n",
        "    block = block_size \n",
        "    )\n",
        "end_t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "4oYsfK4twr0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fda5849-d376-4109-d7ad-d6b338a346ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time processing: 0.0003235340118408203 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"Time processing: {0} seconds\".format(end_t-start_t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "l9M4o9k5xTwt"
      },
      "outputs": [],
      "source": [
        "c_cpu_final = c_gpu.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f261xW4C1qgq",
        "outputId": "88542481-4908-403e-8664-a755ab9cb3f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-12.239344  ,  -9.442764  ,  -1.3886307 ,  -3.006447  ,\n",
              "         -0.26099968],\n",
              "       [ -2.9906766 ,  -9.16776   ,   0.18869138,   6.3902507 ,\n",
              "          4.687619  ],\n",
              "       [ -0.7491901 , -12.7215805 ,  12.837054  ,  -2.5493095 ,\n",
              "        -11.776177  ],\n",
              "       [  5.448393  ,   3.0563555 ,  -1.1583443 ,   0.73490596,\n",
              "         -3.0179965 ],\n",
              "       [-12.381034  ,  -8.46078   ,  -0.32425186,  -4.1947765 ,\n",
              "          2.9934554 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "c_cpu[0:5,0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12KFuyKI1qgq",
        "outputId": "64ba2353-965c-48e5-e8ed-bb03729f3acd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-12.239345  ,  -9.442763  ,  -1.3886307 ,  -3.0064464 ,\n",
              "         -0.26099902],\n",
              "       [ -2.9906764 ,  -9.167759  ,   0.18869105,   6.3902507 ,\n",
              "          4.687624  ],\n",
              "       [ -0.74918866, -12.721581  ,  12.837055  ,  -2.5493097 ,\n",
              "        -11.776179  ],\n",
              "       [  5.448392  ,   3.0563555 ,  -1.1583446 ,   0.73490703,\n",
              "         -3.0179973 ],\n",
              "       [-12.381033  ,  -8.460781  ,  -0.3242505 ,  -4.1947765 ,\n",
              "          2.9934556 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "c_cpu_final[0:5,0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "dgDEdzSV1qgq"
      },
      "outputs": [],
      "source": [
        "MSE = np.sum(np.sum(np.power(c_cpu_final-d,2)))/(d.shape[0]*d.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "R0N5pvPffnqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751a4325-6453-4d93-b03c-ebbb54c41123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error: 1072.0140380859375\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean Square Error: {0}\".format(MSE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EIiYtHHgVTd"
      },
      "source": [
        "# PRACTICAL WORK:\n",
        "\n",
        "Modify the previous code to recieive any dimensional matrices, and be able to multipy them using tiled memory.\n",
        "\n",
        "Take care about boundaries in the final matrix, and fill with zeroes the memory places where the original matrices are not defined."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4cMjU8W1qgq"
      },
      "source": [
        "### Conclusions:\n",
        "\n",
        "We can see that the error returned by the algorithm is higher when the difference between the number of rows and columns is bigger. For example, it returns a higher error when we run the algorithm with matrix A = 1024x50 and matrix B = 50x1024."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}